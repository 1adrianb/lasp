***************
** Arguments **
***************
backbone: 
config_file: configs/LASP/vit_b16_c4_ep300_batch32_cls_t2t_5_wcl_25_g1_b_lr32.yaml
dataset_config_file: configs/datasets/eurosat.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['DATASET.NUM_SHOTS', '16', 'DATASET.SUBSAMPLE_CLASSES', 'base']
output_dir: output/base2new/train_base/eurosat/shots_16/LASP/vit_b16_c4_ep300_batch32_cls_t2t_5_wcl_25_g1_b_lr32/seed2
resume: 
root: /home/work/shared-fi-datasets-01/users/adrian.bulat/data/fs_datasets/
seed: 2
source_domains: None
target_domains: None
trainer: LASP
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 8
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 32
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  INCLUDE_ALL_CLASSES: False
  NAME: EuroSAT
  NUM_LABELED: -1
  NUM_SHOTS: 16
  ROOT: /home/work/shared-fi-datasets-01/users/adrian.bulat/data/fs_datasets/
  SOURCE_DOMAINS: ()
  STL10_FOLD: -1
  SUBSAMPLE_CLASSES: base
  TARGET_DOMAINS: ()
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: ViT-B/16
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.032
  LR_SCHEDULER: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 7
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: constant
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/base2new/train_base/eurosat/shots_16/LASP/vit_b16_c4_ep300_batch32_cls_t2t_5_wcl_25_g1_b_lr32/seed2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 20
TRAINER:
  CDAC:
    CLASS_LR_MULTI: 10
    P_THRESH: 0.95
    RAMPUP_COEF: 30
    RAMPUP_ITRS: 1000
    STRONG_TRANSFORMS: ()
    TOPK_MATCH: 5
  CROSSGRAD:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAELDG:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  DOMAINMIX:
    ALPHA: 1.0
    BETA: 1.0
    TYPE: crossdomain
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  LASP:
    CTX_INIT: a photo of a
    ENABLE: True
    ENABLE_CORRECTION: True
    ENABLE_IMPLICIT_OP: sum
    FINETUNE_VIT_LN: True
    LASP_LOSS_WEIGHT: 5.0
    LASP_PROMPTS: ['a photo of a {}, a type of flower.', 'a photo of a person doing {}.', 'a centered satellite photo of {}.', 'a photo of a {}, a type of aircraft.', '{} texture.', 'itap of a {}.', 'a bad photo of the {}.', 'a origami {}.', 'a photo of the large {}.', 'a {} in a video game.', 'art of the {}.', 'a photo of the small {}.', 'a photo of a {}.', 'a photo of many {}.', 'a photo of the hard to see {}.', 'a low resolution photo of the {}.', 'a rendering of a {}.', 'a bad photo of the {}.', 'a cropped photo of the {}.', 'a pixelated photo of the {}.', 'a bright photo of the {}.', 'a cropped photo of a {}.', 'a photo of the {}.', 'a good photo of the {}.', 'a rendering of the {}.', 'a close-up photo of the {}.', 'a low resolution photo of a {}.', 'a rendition of the {}.', 'a photo of the clean {}.', 'a photo of a large {}.', 'a blurry photo of a {}.', 'a pixelated photo of a {}.', 'itap of the {}.', 'a jpeg corrupted photo of the {}.', 'a good photo of a {}.']
    N_CTX: 4
    PREC: amp
    PRETRAINED_PROMPTS_DIR: None
    TRAIN_W: True
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEACHER:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: LASP
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.0
Is debug build: False
CUDA used to build PyTorch: 11.8
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.4 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
Clang version: Could not collect
CMake version: version 3.18.4
Libc version: glibc-2.31

Python version: 3.10.9 (main, Mar  8 2023, 10:47:38) [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-100-generic-x86_64-with-glibc2.31
Is CUDA available: True
CUDA runtime version: 11.7.64
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: CUDA GPU
GPU 1: CUDA GPU
GPU 2: CUDA GPU
GPU 3: CUDA GPU

Nvidia driver version: 520.61.05
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.4.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.4.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.4.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.4.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.4.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.4.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.4.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          128
On-line CPU(s) list:             0-127
Thread(s) per core:              2
Core(s) per socket:              32
Socket(s):                       2
NUMA node(s):                    4
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7452 32-Core Processor
Stepping:                        0
CPU MHz:                         3281.578
BogoMIPS:                        4691.32
Virtualization:                  AMD-V
L1d cache:                       2 MiB
L1i cache:                       2 MiB
L2 cache:                        32 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-15,64-79
NUMA node1 CPU(s):               16-31,80-95
NUMA node2 CPU(s):               32-47,96-111
NUMA node3 CPU(s):               48-63,112-127
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.23.5
[pip3] open-clip-torch==2.16.0
[pip3] torch==2.0.0
[pip3] torchaudio==2.0.0
[pip3] torchvision==0.15.0
[conda] blas                      1.0                         mkl  
[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch
[conda] mkl                       2021.4.0           h06a4308_640  
[conda] mkl-service               2.4.0           py310h7f8727e_0  
[conda] mkl_fft                   1.3.1           py310hd6ae3a3_0  
[conda] mkl_random                1.2.2           py310h00e6091_0  
[conda] numpy                     1.23.5          py310hd5efca6_0  
[conda] numpy-base                1.23.5          py310h8e6c178_0  
[conda] open-clip-torch           2.16.0                    dev_0    <develop>
[conda] pytorch                   2.0.0           py3.10_cuda11.8_cudnn8.7.0_0    pytorch
[conda] pytorch-cuda              11.8                 h7e8668a_3    pytorch
[conda] pytorch-mutex             1.0                        cuda    pytorch
[conda] torchaudio                2.0.0               py310_cu118    pytorch
[conda] torchtriton               2.0.0                     py310    pytorch
[conda] torchvision               0.15.0              py310_cu118    pytorch
        Pillow (9.4.0)

Loading trainer: LASP
Loading dataset: EuroSAT
Reading split from /home/work/shared-fi-datasets-01/users/adrian.bulat/data/fs_datasets/eurosat/split_zhou_EuroSAT.json
Loading preprocessed few-shot data from /home/work/shared-fi-datasets-01/users/adrian.bulat/data/fs_datasets/eurosat/split_fewshot/shot_16-seed_2.pkl
SUBSAMPLE BASE CLASSES!
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    EuroSAT
# classes  5
# train_x  80
# val      20
# test     4,200
---------  -------
Loading CLIP (backbone: ViT-B/16)
Building custom CLIP
Initial context: "a photo of a"
Number of context words (tokens): 4
Initializing LASP prompts...
Num classes used for LASP: 10
Turning off gradients in both the image and the text encoder
Re-enabling LN...
Parameters to be updated: {'image_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'prompt_learner.w', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'prompt_learner.ctx', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias'}
Loading evaluator: Classification
Note that load_model() is skipped as no pretrained model is given
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/base2new/train_base/eurosat/shots_16/LASP/vit_b16_c4_ep300_batch32_cls_t2t_5_wcl_25_g1_b_lr32/seed2/tensorboard)
epoch [1/300] batch [1/2] time 1.493 (1.493) data 0.645 (0.645) loss 1.8677 (1.8677) lr 1.0000e-05 eta 0:14:54
epoch [1/300] batch [2/2] time 0.076 (0.785) data 0.000 (0.323) loss 1.6602 (1.7640) lr 1.0000e-05 eta 0:07:49
epoch [2/300] batch [1/2] time 0.149 (0.149) data 0.075 (0.075) loss 1.6232 (1.6232) lr 1.0000e-05 eta 0:01:29
epoch [2/300] batch [2/2] time 0.073 (0.111) data 0.000 (0.038) loss 1.7683 (1.6957) lr 1.0000e-05 eta 0:01:06
epoch [3/300] batch [1/2] time 0.145 (0.145) data 0.070 (0.070) loss 1.9678 (1.9678) lr 1.0000e-05 eta 0:01:26
epoch [3/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 1.9141 (1.9409) lr 1.0000e-05 eta 0:01:04
epoch [4/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 1.9930 (1.9930) lr 1.0000e-05 eta 0:01:26
epoch [4/300] batch [2/2] time 0.074 (0.110) data 0.000 (0.036) loss 1.7937 (1.8934) lr 1.0000e-05 eta 0:01:05
epoch [5/300] batch [1/2] time 0.144 (0.144) data 0.070 (0.070) loss 1.7001 (1.7001) lr 1.0000e-05 eta 0:01:25
epoch [5/300] batch [2/2] time 0.074 (0.109) data 0.000 (0.035) loss 2.0391 (1.8696) lr 1.0000e-05 eta 0:01:04
epoch [6/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 1.9153 (1.9153) lr 1.0000e-05 eta 0:01:25
epoch [6/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 1.9069 (1.9111) lr 1.0000e-05 eta 0:01:04
epoch [7/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 1.7196 (1.7196) lr 1.0000e-05 eta 0:01:25
epoch [7/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 1.7914 (1.7555) lr 3.2000e-03 eta 0:01:04
epoch [8/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 1.9596 (1.9596) lr 3.2000e-03 eta 0:01:24
epoch [8/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 1.8772 (1.9184) lr 3.1999e-03 eta 0:01:03
epoch [9/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 1.4041 (1.4041) lr 3.1999e-03 eta 0:01:24
epoch [9/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 1.2804 (1.3422) lr 3.1996e-03 eta 0:01:03
epoch [10/300] batch [1/2] time 0.144 (0.144) data 0.070 (0.070) loss 1.7040 (1.7040) lr 3.1996e-03 eta 0:01:23
epoch [10/300] batch [2/2] time 0.073 (0.108) data 0.000 (0.035) loss 1.3534 (1.5287) lr 3.1992e-03 eta 0:01:02
epoch [11/300] batch [1/2] time 0.144 (0.144) data 0.070 (0.070) loss 1.2968 (1.2968) lr 3.1992e-03 eta 0:01:23
epoch [11/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 1.3707 (1.3338) lr 3.1986e-03 eta 0:01:02
epoch [12/300] batch [1/2] time 0.146 (0.146) data 0.072 (0.072) loss 1.3454 (1.3454) lr 3.1986e-03 eta 0:01:24
epoch [12/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 1.1892 (1.2673) lr 3.1978e-03 eta 0:01:03
epoch [13/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 1.4197 (1.4197) lr 3.1978e-03 eta 0:01:23
epoch [13/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.8513 (1.1355) lr 3.1968e-03 eta 0:01:02
epoch [14/300] batch [1/2] time 0.144 (0.144) data 0.070 (0.070) loss 0.9967 (0.9967) lr 3.1968e-03 eta 0:01:22
epoch [14/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.7790 (0.8879) lr 3.1957e-03 eta 0:01:02
epoch [15/300] batch [1/2] time 0.141 (0.141) data 0.067 (0.067) loss 0.9359 (0.9359) lr 3.1957e-03 eta 0:01:20
epoch [15/300] batch [2/2] time 0.074 (0.107) data 0.000 (0.034) loss 0.8485 (0.8922) lr 3.1944e-03 eta 0:01:01
epoch [16/300] batch [1/2] time 0.143 (0.143) data 0.068 (0.068) loss 0.7660 (0.7660) lr 3.1944e-03 eta 0:01:21
epoch [16/300] batch [2/2] time 0.074 (0.108) data 0.000 (0.034) loss 0.8163 (0.7911) lr 3.1929e-03 eta 0:01:01
epoch [17/300] batch [1/2] time 0.148 (0.148) data 0.074 (0.074) loss 0.6041 (0.6041) lr 3.1929e-03 eta 0:01:23
epoch [17/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.037) loss 0.9993 (0.8017) lr 3.1912e-03 eta 0:01:02
epoch [18/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.6692 (0.6692) lr 3.1912e-03 eta 0:01:22
epoch [18/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.6254 (0.6473) lr 3.1894e-03 eta 0:01:01
epoch [19/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.9075 (0.9075) lr 3.1894e-03 eta 0:01:21
epoch [19/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.6300 (0.7687) lr 3.1874e-03 eta 0:01:01
epoch [20/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.8398 (0.8398) lr 3.1874e-03 eta 0:01:21
epoch [20/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.5656 (0.7027) lr 3.1852e-03 eta 0:01:01
epoch [21/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.5345 (0.5345) lr 3.1852e-03 eta 0:01:21
epoch [21/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.6669 (0.6007) lr 3.1828e-03 eta 0:01:00
epoch [22/300] batch [1/2] time 0.146 (0.146) data 0.072 (0.072) loss 1.0693 (1.0693) lr 3.1828e-03 eta 0:01:21
epoch [22/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.3726 (0.7209) lr 3.1803e-03 eta 0:01:00
epoch [23/300] batch [1/2] time 0.147 (0.147) data 0.073 (0.073) loss 0.7193 (0.7193) lr 3.1803e-03 eta 0:01:21
epoch [23/300] batch [2/2] time 0.071 (0.109) data 0.000 (0.037) loss 0.9229 (0.8211) lr 3.1776e-03 eta 0:01:00
epoch [24/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.6761 (0.6761) lr 3.1776e-03 eta 0:01:20
epoch [24/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.7107 (0.6934) lr 3.1747e-03 eta 0:00:59
epoch [25/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.5383 (0.5383) lr 3.1747e-03 eta 0:01:19
epoch [25/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.5223 (0.5303) lr 3.1717e-03 eta 0:00:59
epoch [26/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.7425 (0.7425) lr 3.1717e-03 eta 0:01:19
epoch [26/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.035) loss 0.4914 (0.6169) lr 3.1684e-03 eta 0:00:58
epoch [27/300] batch [1/2] time 0.149 (0.149) data 0.075 (0.075) loss 0.6097 (0.6097) lr 3.1684e-03 eta 0:01:21
epoch [27/300] batch [2/2] time 0.071 (0.110) data 0.000 (0.037) loss 0.7722 (0.6909) lr 3.1650e-03 eta 0:01:00
epoch [28/300] batch [1/2] time 0.149 (0.149) data 0.076 (0.076) loss 0.4520 (0.4520) lr 3.1650e-03 eta 0:01:21
epoch [28/300] batch [2/2] time 0.071 (0.110) data 0.000 (0.038) loss 0.6934 (0.5727) lr 3.1615e-03 eta 0:00:59
epoch [29/300] batch [1/2] time 0.147 (0.147) data 0.073 (0.073) loss 0.4405 (0.4405) lr 3.1615e-03 eta 0:01:19
epoch [29/300] batch [2/2] time 0.071 (0.109) data 0.000 (0.037) loss 0.3615 (0.4010) lr 3.1577e-03 eta 0:00:59
epoch [30/300] batch [1/2] time 0.147 (0.147) data 0.074 (0.074) loss 0.6864 (0.6864) lr 3.1577e-03 eta 0:01:19
epoch [30/300] batch [2/2] time 0.071 (0.109) data 0.000 (0.037) loss 0.6413 (0.6639) lr 3.1538e-03 eta 0:00:58
epoch [31/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.6812 (0.6812) lr 3.1538e-03 eta 0:01:17
epoch [31/300] batch [2/2] time 0.072 (0.108) data 0.000 (0.036) loss 0.6117 (0.6465) lr 3.1497e-03 eta 0:00:58
epoch [32/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.2865 (0.2865) lr 3.1497e-03 eta 0:01:17
epoch [32/300] batch [2/2] time 0.072 (0.108) data 0.000 (0.036) loss 0.4799 (0.3832) lr 3.1455e-03 eta 0:00:58
epoch [33/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.7196 (0.7196) lr 3.1455e-03 eta 0:01:17
epoch [33/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.4765 (0.5981) lr 3.1411e-03 eta 0:00:57
epoch [34/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.4386 (0.4386) lr 3.1411e-03 eta 0:01:16
epoch [34/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.3025 (0.3706) lr 3.1365e-03 eta 0:00:57
epoch [35/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.2488 (0.2488) lr 3.1365e-03 eta 0:01:16
epoch [35/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.7108 (0.4798) lr 3.1317e-03 eta 0:00:57
epoch [36/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.4314 (0.4314) lr 3.1317e-03 eta 0:01:15
epoch [36/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.035) loss 0.9220 (0.6767) lr 3.1268e-03 eta 0:00:56
epoch [37/300] batch [1/2] time 0.149 (0.149) data 0.075 (0.075) loss 0.3593 (0.3593) lr 3.1268e-03 eta 0:01:18
epoch [37/300] batch [2/2] time 0.071 (0.110) data 0.000 (0.037) loss 0.2038 (0.2815) lr 3.1217e-03 eta 0:00:57
epoch [38/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.5481 (0.5481) lr 3.1217e-03 eta 0:01:16
epoch [38/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.5937 (0.5709) lr 3.1164e-03 eta 0:00:56
epoch [39/300] batch [1/2] time 0.145 (0.145) data 0.073 (0.073) loss 0.3084 (0.3084) lr 3.1164e-03 eta 0:01:16
epoch [39/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.2491 (0.2788) lr 3.1110e-03 eta 0:00:56
epoch [40/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.4741 (0.4741) lr 3.1110e-03 eta 0:01:13
epoch [40/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.7219 (0.5980) lr 3.1054e-03 eta 0:00:55
epoch [41/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.4981 (0.4981) lr 3.1054e-03 eta 0:01:13
epoch [41/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1929 (0.3455) lr 3.0997e-03 eta 0:00:55
epoch [42/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4409 (0.4409) lr 3.0997e-03 eta 0:01:13
epoch [42/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.8458 (0.6434) lr 3.0937e-03 eta 0:00:55
epoch [43/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.1830 (0.1830) lr 3.0937e-03 eta 0:01:12
epoch [43/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.3098 (0.2464) lr 3.0876e-03 eta 0:00:54
epoch [44/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2808 (0.2808) lr 3.0876e-03 eta 0:01:12
epoch [44/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.8172 (0.5490) lr 3.0814e-03 eta 0:00:54
epoch [45/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.2061 (0.2061) lr 3.0814e-03 eta 0:01:12
epoch [45/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2088 (0.2074) lr 3.0750e-03 eta 0:00:54
epoch [46/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4048 (0.4048) lr 3.0750e-03 eta 0:01:12
epoch [46/300] batch [2/2] time 0.072 (0.107) data 0.000 (0.035) loss 0.4388 (0.4218) lr 3.0684e-03 eta 0:00:54
epoch [47/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.2488 (0.2488) lr 3.0684e-03 eta 0:01:11
epoch [47/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.5403 (0.3946) lr 3.0617e-03 eta 0:00:53
epoch [48/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2060 (0.2060) lr 3.0617e-03 eta 0:01:11
epoch [48/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.8700 (0.5380) lr 3.0548e-03 eta 0:00:53
epoch [49/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2118 (0.2118) lr 3.0548e-03 eta 0:01:11
epoch [49/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.6698 (0.4408) lr 3.0477e-03 eta 0:00:53
epoch [50/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2181 (0.2181) lr 3.0477e-03 eta 0:01:11
epoch [50/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.035) loss 0.2683 (0.2432) lr 3.0405e-03 eta 0:00:53
epoch [51/300] batch [1/2] time 0.143 (0.143) data 0.071 (0.071) loss 0.3392 (0.3392) lr 3.0405e-03 eta 0:01:11
epoch [51/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4645 (0.4018) lr 3.0331e-03 eta 0:00:53
epoch [52/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3244 (0.3244) lr 3.0331e-03 eta 0:01:10
epoch [52/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2500 (0.2872) lr 3.0256e-03 eta 0:00:52
epoch [53/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.6633 (0.6633) lr 3.0256e-03 eta 0:01:10
epoch [53/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1758 (0.4196) lr 3.0179e-03 eta 0:00:53
epoch [54/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.2507 (0.2507) lr 3.0179e-03 eta 0:01:09
epoch [54/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1760 (0.2134) lr 3.0101e-03 eta 0:00:52
epoch [55/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.5716 (0.5716) lr 3.0101e-03 eta 0:01:09
epoch [55/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2530 (0.4123) lr 3.0021e-03 eta 0:00:52
epoch [56/300] batch [1/2] time 0.143 (0.143) data 0.071 (0.071) loss 0.3981 (0.3981) lr 3.0021e-03 eta 0:01:09
epoch [56/300] batch [2/2] time 0.072 (0.108) data 0.000 (0.036) loss 0.3169 (0.3575) lr 2.9939e-03 eta 0:00:52
epoch [57/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2843 (0.2843) lr 2.9939e-03 eta 0:01:09
epoch [57/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.5717 (0.4280) lr 2.9856e-03 eta 0:00:52
epoch [58/300] batch [1/2] time 0.142 (0.142) data 0.072 (0.072) loss 0.2179 (0.2179) lr 2.9856e-03 eta 0:01:09
epoch [58/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.5236 (0.3707) lr 2.9772e-03 eta 0:00:51
epoch [59/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.3090 (0.3090) lr 2.9772e-03 eta 0:01:09
epoch [59/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2528 (0.2809) lr 2.9686e-03 eta 0:00:51
epoch [60/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.3952 (0.3952) lr 2.9686e-03 eta 0:01:08
epoch [60/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2985 (0.3468) lr 2.9598e-03 eta 0:00:51
epoch [61/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3877 (0.3877) lr 2.9598e-03 eta 0:01:07
epoch [61/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.3621 (0.3749) lr 2.9509e-03 eta 0:00:50
epoch [62/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3588 (0.3588) lr 2.9509e-03 eta 0:01:07
epoch [62/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.3861 (0.3725) lr 2.9419e-03 eta 0:00:50
epoch [63/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.1298 (0.1298) lr 2.9419e-03 eta 0:01:08
epoch [63/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4856 (0.3077) lr 2.9327e-03 eta 0:00:50
epoch [64/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1516 (0.1516) lr 2.9327e-03 eta 0:01:06
epoch [64/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.5292 (0.3404) lr 2.9233e-03 eta 0:00:49
epoch [65/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2649 (0.2649) lr 2.9233e-03 eta 0:01:06
epoch [65/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4095 (0.3372) lr 2.9138e-03 eta 0:00:50
epoch [66/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1568 (0.1568) lr 2.9138e-03 eta 0:01:06
epoch [66/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.7451 (0.4510) lr 2.9042e-03 eta 0:00:49
epoch [67/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.6117 (0.6117) lr 2.9042e-03 eta 0:01:06
epoch [67/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0869 (0.3493) lr 2.8944e-03 eta 0:00:49
epoch [68/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2767 (0.2767) lr 2.8944e-03 eta 0:01:05
epoch [68/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4279 (0.3523) lr 2.8845e-03 eta 0:00:49
epoch [69/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1565 (0.1565) lr 2.8845e-03 eta 0:01:05
epoch [69/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1860 (0.1713) lr 2.8744e-03 eta 0:00:49
epoch [70/300] batch [1/2] time 0.139 (0.139) data 0.068 (0.068) loss 0.4127 (0.4127) lr 2.8744e-03 eta 0:01:04
epoch [70/300] batch [2/2] time 0.071 (0.105) data 0.000 (0.034) loss 0.4102 (0.4115) lr 2.8642e-03 eta 0:00:48
epoch [71/300] batch [1/2] time 0.144 (0.144) data 0.073 (0.073) loss 0.2273 (0.2273) lr 2.8642e-03 eta 0:01:06
epoch [71/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.037) loss 0.1369 (0.1821) lr 2.8539e-03 eta 0:00:49
epoch [72/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.5787 (0.5787) lr 2.8539e-03 eta 0:01:05
epoch [72/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.6056 (0.5921) lr 2.8434e-03 eta 0:00:48
epoch [73/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2958 (0.2958) lr 2.8434e-03 eta 0:01:04
epoch [73/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3315 (0.3136) lr 2.8328e-03 eta 0:00:48
epoch [74/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2143 (0.2143) lr 2.8328e-03 eta 0:01:04
epoch [74/300] batch [2/2] time 0.070 (0.106) data 0.000 (0.036) loss 0.2539 (0.2341) lr 2.8221e-03 eta 0:00:47
epoch [75/300] batch [1/2] time 0.153 (0.153) data 0.081 (0.081) loss 0.4267 (0.4267) lr 2.8221e-03 eta 0:01:08
epoch [75/300] batch [2/2] time 0.071 (0.112) data 0.000 (0.041) loss 0.1793 (0.3030) lr 2.8112e-03 eta 0:00:50
epoch [76/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4363 (0.4363) lr 2.8112e-03 eta 0:01:03
epoch [76/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1161 (0.2762) lr 2.8002e-03 eta 0:00:47
epoch [77/300] batch [1/2] time 0.142 (0.142) data 0.072 (0.072) loss 0.5093 (0.5093) lr 2.8002e-03 eta 0:01:03
epoch [77/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4078 (0.4585) lr 2.7890e-03 eta 0:00:47
epoch [78/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3600 (0.3600) lr 2.7890e-03 eta 0:01:03
epoch [78/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.1893 (0.2746) lr 2.7778e-03 eta 0:00:47
epoch [79/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.1364 (0.1364) lr 2.7778e-03 eta 0:01:03
epoch [79/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1703 (0.1533) lr 2.7663e-03 eta 0:00:47
epoch [80/300] batch [1/2] time 0.143 (0.143) data 0.070 (0.070) loss 0.5701 (0.5701) lr 2.7663e-03 eta 0:01:03
epoch [80/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.035) loss 0.7310 (0.6505) lr 2.7548e-03 eta 0:00:47
epoch [81/300] batch [1/2] time 0.144 (0.144) data 0.073 (0.073) loss 0.2632 (0.2632) lr 2.7548e-03 eta 0:01:03
epoch [81/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1038 (0.1835) lr 2.7432e-03 eta 0:00:47
epoch [82/300] batch [1/2] time 0.142 (0.142) data 0.072 (0.072) loss 0.2262 (0.2262) lr 2.7432e-03 eta 0:01:02
epoch [82/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3402 (0.2832) lr 2.7314e-03 eta 0:00:46
epoch [83/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4398 (0.4398) lr 2.7314e-03 eta 0:01:01
epoch [83/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3738 (0.4068) lr 2.7195e-03 eta 0:00:46
epoch [84/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1119 (0.1119) lr 2.7195e-03 eta 0:01:01
epoch [84/300] batch [2/2] time 0.072 (0.106) data 0.000 (0.035) loss 0.2982 (0.2050) lr 2.7074e-03 eta 0:00:45
epoch [85/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1499 (0.1499) lr 2.7074e-03 eta 0:01:00
epoch [85/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2268 (0.1884) lr 2.6953e-03 eta 0:00:45
epoch [86/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.2301 (0.2301) lr 2.6953e-03 eta 0:01:00
epoch [86/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.5446 (0.3873) lr 2.6830e-03 eta 0:00:45
epoch [87/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2611 (0.2611) lr 2.6830e-03 eta 0:01:01
epoch [87/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2280 (0.2445) lr 2.6706e-03 eta 0:00:45
epoch [88/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3404 (0.3404) lr 2.6706e-03 eta 0:01:00
epoch [88/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3378 (0.3391) lr 2.6581e-03 eta 0:00:45
epoch [89/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1908 (0.1908) lr 2.6581e-03 eta 0:01:00
epoch [89/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1477 (0.1692) lr 2.6455e-03 eta 0:00:44
epoch [90/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.3226 (0.3226) lr 2.6455e-03 eta 0:00:59
epoch [90/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.3897 (0.3562) lr 2.6327e-03 eta 0:00:44
epoch [91/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2486 (0.2486) lr 2.6327e-03 eta 0:00:59
epoch [91/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4722 (0.3604) lr 2.6199e-03 eta 0:00:44
epoch [92/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2546 (0.2546) lr 2.6199e-03 eta 0:00:59
epoch [92/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1481 (0.2013) lr 2.6069e-03 eta 0:00:44
epoch [93/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1223 (0.1223) lr 2.6069e-03 eta 0:00:58
epoch [93/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4532 (0.2878) lr 2.5938e-03 eta 0:00:44
epoch [94/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.0948 (0.0948) lr 2.5938e-03 eta 0:00:58
epoch [94/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4024 (0.2486) lr 2.5807e-03 eta 0:00:43
epoch [95/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4596 (0.4596) lr 2.5807e-03 eta 0:00:58
epoch [95/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1167 (0.2882) lr 2.5674e-03 eta 0:00:43
epoch [96/300] batch [1/2] time 0.146 (0.146) data 0.075 (0.075) loss 0.3426 (0.3426) lr 2.5674e-03 eta 0:00:59
epoch [96/300] batch [2/2] time 0.071 (0.109) data 0.000 (0.037) loss 0.3184 (0.3305) lr 2.5540e-03 eta 0:00:44
epoch [97/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2757 (0.2757) lr 2.5540e-03 eta 0:00:57
epoch [97/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.6487 (0.4622) lr 2.5405e-03 eta 0:00:43
epoch [98/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3297 (0.3297) lr 2.5405e-03 eta 0:00:57
epoch [98/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3619 (0.3458) lr 2.5268e-03 eta 0:00:43
epoch [99/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2274 (0.2274) lr 2.5268e-03 eta 0:00:56
epoch [99/300] batch [2/2] time 0.072 (0.107) data 0.000 (0.035) loss 0.4220 (0.3247) lr 2.5131e-03 eta 0:00:42
epoch [100/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.2061 (0.2061) lr 2.5131e-03 eta 0:00:56
epoch [100/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2825 (0.2443) lr 2.4993e-03 eta 0:00:42
epoch [101/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.5353 (0.5353) lr 2.4993e-03 eta 0:00:56
epoch [101/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0842 (0.3098) lr 2.4854e-03 eta 0:00:42
epoch [102/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2848 (0.2848) lr 2.4854e-03 eta 0:00:56
epoch [102/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2249 (0.2548) lr 2.4714e-03 eta 0:00:42
epoch [103/300] batch [1/2] time 0.142 (0.142) data 0.072 (0.072) loss 0.1662 (0.1662) lr 2.4714e-03 eta 0:00:56
epoch [103/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2134 (0.1898) lr 2.4573e-03 eta 0:00:42
epoch [104/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.5502 (0.5502) lr 2.4573e-03 eta 0:00:55
epoch [104/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1868 (0.3685) lr 2.4431e-03 eta 0:00:41
epoch [105/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4803 (0.4803) lr 2.4431e-03 eta 0:00:55
epoch [105/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1539 (0.3171) lr 2.4288e-03 eta 0:00:41
epoch [106/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1554 (0.1554) lr 2.4288e-03 eta 0:00:54
epoch [106/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2966 (0.2260) lr 2.4145e-03 eta 0:00:41
epoch [107/300] batch [1/2] time 0.146 (0.146) data 0.073 (0.073) loss 0.3028 (0.3028) lr 2.4145e-03 eta 0:00:56
epoch [107/300] batch [2/2] time 0.071 (0.109) data 0.000 (0.037) loss 0.0785 (0.1906) lr 2.4000e-03 eta 0:00:41
epoch [108/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.3649 (0.3649) lr 2.4000e-03 eta 0:00:54
epoch [108/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1277 (0.2463) lr 2.3854e-03 eta 0:00:40
epoch [109/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1191 (0.1191) lr 2.3854e-03 eta 0:00:54
epoch [109/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.035) loss 0.3552 (0.2371) lr 2.3708e-03 eta 0:00:40
epoch [110/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4164 (0.4164) lr 2.3708e-03 eta 0:00:53
epoch [110/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4327 (0.4246) lr 2.3561e-03 eta 0:00:40
epoch [111/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2244 (0.2244) lr 2.3561e-03 eta 0:00:53
epoch [111/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2444 (0.2344) lr 2.3413e-03 eta 0:00:40
epoch [112/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1748 (0.1748) lr 2.3413e-03 eta 0:00:53
epoch [112/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1927 (0.1837) lr 2.3264e-03 eta 0:00:40
epoch [113/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1809 (0.1809) lr 2.3264e-03 eta 0:00:52
epoch [113/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1449 (0.1629) lr 2.3114e-03 eta 0:00:39
epoch [114/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4269 (0.4269) lr 2.3114e-03 eta 0:00:52
epoch [114/300] batch [2/2] time 0.072 (0.107) data 0.000 (0.035) loss 0.0532 (0.2400) lr 2.2964e-03 eta 0:00:39
epoch [115/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.0502 (0.0502) lr 2.2964e-03 eta 0:00:52
epoch [115/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.1888 (0.1195) lr 2.2812e-03 eta 0:00:39
epoch [116/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.1151 (0.1151) lr 2.2812e-03 eta 0:00:53
epoch [116/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.4765 (0.2958) lr 2.2660e-03 eta 0:00:39
epoch [117/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.5117 (0.5117) lr 2.2660e-03 eta 0:00:52
epoch [117/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4426 (0.4772) lr 2.2508e-03 eta 0:00:39
epoch [118/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3300 (0.3300) lr 2.2508e-03 eta 0:00:51
epoch [118/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.0902 (0.2101) lr 2.2354e-03 eta 0:00:38
epoch [119/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2221 (0.2221) lr 2.2354e-03 eta 0:00:51
epoch [119/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2192 (0.2206) lr 2.2200e-03 eta 0:00:38
epoch [120/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3109 (0.3109) lr 2.2200e-03 eta 0:00:51
epoch [120/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1770 (0.2439) lr 2.2045e-03 eta 0:00:38
epoch [121/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1464 (0.1464) lr 2.2045e-03 eta 0:00:50
epoch [121/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1282 (0.1373) lr 2.1890e-03 eta 0:00:38
epoch [122/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2987 (0.2987) lr 2.1890e-03 eta 0:00:50
epoch [122/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3868 (0.3427) lr 2.1734e-03 eta 0:00:37
epoch [123/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.0464 (0.0464) lr 2.1734e-03 eta 0:00:50
epoch [123/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.3859 (0.2161) lr 2.1577e-03 eta 0:00:37
epoch [124/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.3470 (0.3470) lr 2.1577e-03 eta 0:00:50
epoch [124/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0717 (0.2093) lr 2.1420e-03 eta 0:00:37
epoch [125/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1721 (0.1721) lr 2.1420e-03 eta 0:00:49
epoch [125/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.3776 (0.2748) lr 2.1262e-03 eta 0:00:37
epoch [126/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1400 (0.1400) lr 2.1262e-03 eta 0:00:49
epoch [126/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0715 (0.1057) lr 2.1103e-03 eta 0:00:37
epoch [127/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2793 (0.2793) lr 2.1103e-03 eta 0:00:49
epoch [127/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2462 (0.2627) lr 2.0944e-03 eta 0:00:36
epoch [128/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.3693 (0.3693) lr 2.0944e-03 eta 0:00:49
epoch [128/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1069 (0.2381) lr 2.0785e-03 eta 0:00:36
epoch [129/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2249 (0.2249) lr 2.0785e-03 eta 0:00:48
epoch [129/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.2346 (0.2297) lr 2.0625e-03 eta 0:00:36
epoch [130/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2875 (0.2875) lr 2.0625e-03 eta 0:00:48
epoch [130/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2025 (0.2450) lr 2.0464e-03 eta 0:00:36
epoch [131/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1007 (0.1007) lr 2.0464e-03 eta 0:00:47
epoch [131/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4720 (0.2863) lr 2.0303e-03 eta 0:00:35
epoch [132/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2161 (0.2161) lr 2.0303e-03 eta 0:00:47
epoch [132/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3108 (0.2634) lr 2.0141e-03 eta 0:00:35
epoch [133/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.1562 (0.1562) lr 2.0141e-03 eta 0:00:47
epoch [133/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0655 (0.1109) lr 1.9979e-03 eta 0:00:35
epoch [134/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2063 (0.2063) lr 1.9979e-03 eta 0:00:46
epoch [134/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1067 (0.1565) lr 1.9817e-03 eta 0:00:35
epoch [135/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.7158 (0.7158) lr 1.9817e-03 eta 0:00:46
epoch [135/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4130 (0.5644) lr 1.9654e-03 eta 0:00:34
epoch [136/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.4614 (0.4614) lr 1.9654e-03 eta 0:00:46
epoch [136/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2913 (0.3763) lr 1.9490e-03 eta 0:00:34
epoch [137/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.1680 (0.1680) lr 1.9490e-03 eta 0:00:46
epoch [137/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2022 (0.1851) lr 1.9327e-03 eta 0:00:34
epoch [138/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2888 (0.2888) lr 1.9327e-03 eta 0:00:45
epoch [138/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1975 (0.2432) lr 1.9163e-03 eta 0:00:34
epoch [139/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1083 (0.1083) lr 1.9163e-03 eta 0:00:45
epoch [139/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1218 (0.1151) lr 1.8998e-03 eta 0:00:34
epoch [140/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1699 (0.1699) lr 1.8998e-03 eta 0:00:45
epoch [140/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1817 (0.1758) lr 1.8833e-03 eta 0:00:34
epoch [141/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1506 (0.1506) lr 1.8833e-03 eta 0:00:45
epoch [141/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1095 (0.1301) lr 1.8668e-03 eta 0:00:33
epoch [142/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.5634 (0.5634) lr 1.8668e-03 eta 0:00:44
epoch [142/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.1391 (0.3512) lr 1.8503e-03 eta 0:00:33
epoch [143/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.1255 (0.1255) lr 1.8503e-03 eta 0:00:44
epoch [143/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4098 (0.2676) lr 1.8337e-03 eta 0:00:33
epoch [144/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.4374 (0.4374) lr 1.8337e-03 eta 0:00:44
epoch [144/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0477 (0.2426) lr 1.8171e-03 eta 0:00:33
epoch [145/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.7827 (0.7827) lr 1.8171e-03 eta 0:00:44
epoch [145/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1979 (0.4903) lr 1.8005e-03 eta 0:00:32
epoch [146/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2670 (0.2670) lr 1.8005e-03 eta 0:00:43
epoch [146/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2820 (0.2745) lr 1.7839e-03 eta 0:00:32
epoch [147/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3204 (0.3204) lr 1.7839e-03 eta 0:00:43
epoch [147/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.0855 (0.2030) lr 1.7672e-03 eta 0:00:32
epoch [148/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.3606 (0.3606) lr 1.7672e-03 eta 0:00:43
epoch [148/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0633 (0.2119) lr 1.7506e-03 eta 0:00:32
epoch [149/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2449 (0.2449) lr 1.7506e-03 eta 0:00:42
epoch [149/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1502 (0.1976) lr 1.7339e-03 eta 0:00:32
epoch [150/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2481 (0.2481) lr 1.7339e-03 eta 0:00:42
epoch [150/300] batch [2/2] time 0.072 (0.106) data 0.000 (0.035) loss 0.2070 (0.2276) lr 1.7172e-03 eta 0:00:31
epoch [151/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1701 (0.1701) lr 1.7172e-03 eta 0:00:42
epoch [151/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2564 (0.2133) lr 1.7005e-03 eta 0:00:31
epoch [152/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.5271 (0.5271) lr 1.7005e-03 eta 0:00:42
epoch [152/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.5997 (0.5634) lr 1.6837e-03 eta 0:00:31
epoch [153/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2372 (0.2372) lr 1.6837e-03 eta 0:00:41
epoch [153/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2214 (0.2293) lr 1.6670e-03 eta 0:00:31
epoch [154/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.3122 (0.3122) lr 1.6670e-03 eta 0:00:41
epoch [154/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.3689 (0.3406) lr 1.6503e-03 eta 0:00:31
epoch [155/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.0779 (0.0779) lr 1.6503e-03 eta 0:00:41
epoch [155/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0446 (0.0612) lr 1.6335e-03 eta 0:00:30
epoch [156/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2444 (0.2444) lr 1.6335e-03 eta 0:00:40
epoch [156/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0863 (0.1653) lr 1.6168e-03 eta 0:00:30
epoch [157/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.5317 (0.5317) lr 1.6168e-03 eta 0:00:40
epoch [157/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3622 (0.4470) lr 1.6000e-03 eta 0:00:30
epoch [158/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1581 (0.1581) lr 1.6000e-03 eta 0:00:40
epoch [158/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4054 (0.2818) lr 1.5832e-03 eta 0:00:30
epoch [159/300] batch [1/2] time 0.141 (0.141) data 0.071 (0.071) loss 0.0968 (0.0968) lr 1.5832e-03 eta 0:00:39
epoch [159/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2959 (0.1963) lr 1.5665e-03 eta 0:00:29
epoch [160/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.1097 (0.1097) lr 1.5665e-03 eta 0:00:39
epoch [160/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.4092 (0.2595) lr 1.5497e-03 eta 0:00:29
epoch [161/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.2463 (0.2463) lr 1.5497e-03 eta 0:00:39
epoch [161/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1829 (0.2146) lr 1.5330e-03 eta 0:00:29
epoch [162/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3603 (0.3603) lr 1.5330e-03 eta 0:00:39
epoch [162/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2150 (0.2876) lr 1.5163e-03 eta 0:00:29
epoch [163/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.4899 (0.4899) lr 1.5163e-03 eta 0:00:38
epoch [163/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1795 (0.3347) lr 1.4995e-03 eta 0:00:29
epoch [164/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.2102 (0.2102) lr 1.4995e-03 eta 0:00:39
epoch [164/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3480 (0.2791) lr 1.4828e-03 eta 0:00:29
epoch [165/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2261 (0.2261) lr 1.4828e-03 eta 0:00:38
epoch [165/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.0938 (0.1599) lr 1.4661e-03 eta 0:00:28
epoch [166/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1625 (0.1625) lr 1.4661e-03 eta 0:00:37
epoch [166/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.2421 (0.2023) lr 1.4494e-03 eta 0:00:28
epoch [167/300] batch [1/2] time 0.143 (0.143) data 0.073 (0.073) loss 0.2900 (0.2900) lr 1.4494e-03 eta 0:00:38
epoch [167/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0485 (0.1693) lr 1.4328e-03 eta 0:00:28
epoch [168/300] batch [1/2] time 0.140 (0.140) data 0.068 (0.068) loss 0.2603 (0.2603) lr 1.4328e-03 eta 0:00:36
epoch [168/300] batch [2/2] time 0.071 (0.105) data 0.000 (0.034) loss 0.4075 (0.3339) lr 1.4161e-03 eta 0:00:27
epoch [169/300] batch [1/2] time 0.144 (0.144) data 0.073 (0.073) loss 0.2229 (0.2229) lr 1.4161e-03 eta 0:00:37
epoch [169/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.037) loss 0.2293 (0.2261) lr 1.3995e-03 eta 0:00:28
epoch [170/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2188 (0.2188) lr 1.3995e-03 eta 0:00:37
epoch [170/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1112 (0.1650) lr 1.3829e-03 eta 0:00:27
epoch [171/300] batch [1/2] time 0.142 (0.142) data 0.072 (0.072) loss 0.0574 (0.0574) lr 1.3829e-03 eta 0:00:36
epoch [171/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3641 (0.2107) lr 1.3663e-03 eta 0:00:27
epoch [172/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.0545 (0.0545) lr 1.3663e-03 eta 0:00:36
epoch [172/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0798 (0.0672) lr 1.3497e-03 eta 0:00:27
epoch [173/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.1568 (0.1568) lr 1.3497e-03 eta 0:00:36
epoch [173/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.5115 (0.3341) lr 1.3332e-03 eta 0:00:27
epoch [174/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2211 (0.2211) lr 1.3332e-03 eta 0:00:35
epoch [174/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.1702 (0.1956) lr 1.3167e-03 eta 0:00:26
epoch [175/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1762 (0.1762) lr 1.3167e-03 eta 0:00:35
epoch [175/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1752 (0.1757) lr 1.3002e-03 eta 0:00:26
epoch [176/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.1549 (0.1549) lr 1.3002e-03 eta 0:00:35
epoch [176/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0520 (0.1035) lr 1.2837e-03 eta 0:00:26
epoch [177/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2625 (0.2625) lr 1.2837e-03 eta 0:00:35
epoch [177/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2385 (0.2505) lr 1.2673e-03 eta 0:00:26
epoch [178/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.1490 (0.1490) lr 1.2673e-03 eta 0:00:35
epoch [178/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1217 (0.1353) lr 1.2510e-03 eta 0:00:26
epoch [179/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2207 (0.2207) lr 1.2510e-03 eta 0:00:34
epoch [179/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1409 (0.1808) lr 1.2346e-03 eta 0:00:25
epoch [180/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2384 (0.2384) lr 1.2346e-03 eta 0:00:34
epoch [180/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2092 (0.2238) lr 1.2183e-03 eta 0:00:25
epoch [181/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2648 (0.2648) lr 1.2183e-03 eta 0:00:34
epoch [181/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1951 (0.2299) lr 1.2021e-03 eta 0:00:25
epoch [182/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.0564 (0.0564) lr 1.2021e-03 eta 0:00:34
epoch [182/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.2482 (0.1523) lr 1.1859e-03 eta 0:00:25
epoch [183/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.1742 (0.1742) lr 1.1859e-03 eta 0:00:33
epoch [183/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0618 (0.1180) lr 1.1697e-03 eta 0:00:25
epoch [184/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.0517 (0.0517) lr 1.1697e-03 eta 0:00:33
epoch [184/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.3318 (0.1918) lr 1.1536e-03 eta 0:00:24
epoch [185/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2031 (0.2031) lr 1.1536e-03 eta 0:00:32
epoch [185/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0571 (0.1301) lr 1.1375e-03 eta 0:00:24
epoch [186/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1086 (0.1086) lr 1.1375e-03 eta 0:00:32
epoch [186/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.035) loss 0.2979 (0.2032) lr 1.1215e-03 eta 0:00:24
epoch [187/300] batch [1/2] time 0.144 (0.144) data 0.072 (0.072) loss 0.3733 (0.3733) lr 1.1215e-03 eta 0:00:32
epoch [187/300] batch [2/2] time 0.071 (0.108) data 0.000 (0.036) loss 0.0723 (0.2228) lr 1.1056e-03 eta 0:00:24
epoch [188/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2327 (0.2327) lr 1.1056e-03 eta 0:00:32
epoch [188/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.1788 (0.2058) lr 1.0897e-03 eta 0:00:23
epoch [189/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2124 (0.2124) lr 1.0897e-03 eta 0:00:31
epoch [189/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0382 (0.1253) lr 1.0738e-03 eta 0:00:23
epoch [190/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.0567 (0.0567) lr 1.0738e-03 eta 0:00:31
epoch [190/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0459 (0.0513) lr 1.0580e-03 eta 0:00:23
epoch [191/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.0691 (0.0691) lr 1.0580e-03 eta 0:00:31
epoch [191/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0271 (0.0481) lr 1.0423e-03 eta 0:00:23
epoch [192/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.3404 (0.3404) lr 1.0423e-03 eta 0:00:31
epoch [192/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0407 (0.1906) lr 1.0266e-03 eta 0:00:23
epoch [193/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2970 (0.2970) lr 1.0266e-03 eta 0:00:30
epoch [193/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.036) loss 0.0829 (0.1900) lr 1.0110e-03 eta 0:00:22
epoch [194/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2454 (0.2454) lr 1.0110e-03 eta 0:00:30
epoch [194/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.3910 (0.3182) lr 9.9545e-04 eta 0:00:22
epoch [195/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2805 (0.2805) lr 9.9545e-04 eta 0:00:30
epoch [195/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2356 (0.2581) lr 9.7998e-04 eta 0:00:22
epoch [196/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3634 (0.3634) lr 9.7998e-04 eta 0:00:29
epoch [196/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.035) loss 0.0950 (0.2292) lr 9.6456e-04 eta 0:00:22
epoch [197/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.1221 (0.1221) lr 9.6456e-04 eta 0:00:29
epoch [197/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.4058 (0.2640) lr 9.4922e-04 eta 0:00:21
epoch [198/300] batch [1/2] time 0.142 (0.142) data 0.070 (0.070) loss 0.1270 (0.1270) lr 9.4922e-04 eta 0:00:29
epoch [198/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.1005 (0.1138) lr 9.3395e-04 eta 0:00:21
epoch [199/300] batch [1/2] time 0.149 (0.149) data 0.078 (0.078) loss 0.0740 (0.0740) lr 9.3395e-04 eta 0:00:30
epoch [199/300] batch [2/2] time 0.071 (0.110) data 0.000 (0.039) loss 0.0535 (0.0638) lr 9.1875e-04 eta 0:00:22
epoch [200/300] batch [1/2] time 0.141 (0.141) data 0.070 (0.070) loss 0.1255 (0.1255) lr 9.1875e-04 eta 0:00:28
epoch [200/300] batch [2/2] time 0.071 (0.106) data 0.000 (0.035) loss 0.3162 (0.2208) lr 9.0363e-04 eta 0:00:21
epoch [201/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.0387 (0.0387) lr 9.0363e-04 eta 0:00:28
epoch [201/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2206 (0.1297) lr 8.8858e-04 eta 0:00:21
epoch [202/300] batch [1/2] time 0.146 (0.146) data 0.074 (0.074) loss 0.0547 (0.0547) lr 8.8858e-04 eta 0:00:28
epoch [202/300] batch [2/2] time 0.071 (0.109) data 0.000 (0.037) loss 0.2791 (0.1669) lr 8.7362e-04 eta 0:00:21
epoch [203/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.2832 (0.2832) lr 8.7362e-04 eta 0:00:27
epoch [203/300] batch [2/2] time 0.072 (0.107) data 0.000 (0.036) loss 0.0323 (0.1577) lr 8.5873e-04 eta 0:00:20
epoch [204/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.0496 (0.0496) lr 8.5873e-04 eta 0:00:27
epoch [204/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0827 (0.0661) lr 8.4392e-04 eta 0:00:20
epoch [205/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.5191 (0.5191) lr 8.4392e-04 eta 0:00:27
epoch [205/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0231 (0.2711) lr 8.2919e-04 eta 0:00:20
epoch [206/300] batch [1/2] time 0.143 (0.143) data 0.072 (0.072) loss 0.0387 (0.0387) lr 8.2919e-04 eta 0:00:26
epoch [206/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0371 (0.0379) lr 8.1455e-04 eta 0:00:20
epoch [207/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.3042 (0.3042) lr 8.1455e-04 eta 0:00:26
epoch [207/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.2490 (0.2766) lr 8.0000e-04 eta 0:00:19
epoch [208/300] batch [1/2] time 0.142 (0.142) data 0.071 (0.071) loss 0.2081 (0.2081) lr 8.0000e-04 eta 0:00:26
epoch [208/300] batch [2/2] time 0.071 (0.107) data 0.000 (0.036) loss 0.0790 (0.1435) lr 7.8553e-04 eta 0:00:19
epoch [209/300] batch [1/2] time 0.147 (0.147) data 0.070 (0.070) loss 0.3171 (0.3171) lr 7.8553e-04 eta 0:00:26
epoch [209/300] batch [2/2] time 0.075 (0.111) data 0.000 (0.035) loss 0.2164 (0.2668) lr 7.7116e-04 eta 0:00:20
epoch [210/300] batch [1/2] time 0.145 (0.145) data 0.070 (0.070) loss 0.1961 (0.1961) lr 7.7116e-04 eta 0:00:26
epoch [210/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.1170 (0.1566) lr 7.5687e-04 eta 0:00:19
epoch [211/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.0231 (0.0231) lr 7.5687e-04 eta 0:00:26
epoch [211/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.2594 (0.1413) lr 7.4268e-04 eta 0:00:19
epoch [212/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.0189 (0.0189) lr 7.4268e-04 eta 0:00:25
epoch [212/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.3468 (0.1828) lr 7.2858e-04 eta 0:00:19
epoch [213/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.1548 (0.1548) lr 7.2858e-04 eta 0:00:25
epoch [213/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.1665 (0.1607) lr 7.1457e-04 eta 0:00:18
epoch [214/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.2252 (0.2252) lr 7.1457e-04 eta 0:00:25
epoch [214/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1945 (0.2098) lr 7.0067e-04 eta 0:00:18
epoch [215/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.0305 (0.0305) lr 7.0067e-04 eta 0:00:24
epoch [215/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0461 (0.0383) lr 6.8686e-04 eta 0:00:18
epoch [216/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.2547 (0.2547) lr 6.8686e-04 eta 0:00:24
epoch [216/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.0962 (0.1755) lr 6.7315e-04 eta 0:00:18
epoch [217/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.0197 (0.0197) lr 6.7315e-04 eta 0:00:24
epoch [217/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.3033 (0.1615) lr 6.5954e-04 eta 0:00:18
epoch [218/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.0947 (0.0947) lr 6.5954e-04 eta 0:00:23
epoch [218/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.1122 (0.1035) lr 6.4604e-04 eta 0:00:17
epoch [219/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.3905 (0.3905) lr 6.4604e-04 eta 0:00:23
epoch [219/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.1690 (0.2797) lr 6.3264e-04 eta 0:00:17
epoch [220/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.1657 (0.1657) lr 6.3264e-04 eta 0:00:23
epoch [220/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0640 (0.1149) lr 6.1935e-04 eta 0:00:17
epoch [221/300] batch [1/2] time 0.144 (0.144) data 0.070 (0.070) loss 0.0202 (0.0202) lr 6.1935e-04 eta 0:00:22
epoch [221/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.2899 (0.1551) lr 6.0616e-04 eta 0:00:17
epoch [222/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.1235 (0.1235) lr 6.0616e-04 eta 0:00:22
epoch [222/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0454 (0.0844) lr 5.9309e-04 eta 0:00:16
epoch [223/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.2312 (0.2312) lr 5.9309e-04 eta 0:00:22
epoch [223/300] batch [2/2] time 0.073 (0.108) data 0.000 (0.035) loss 0.0394 (0.1353) lr 5.8012e-04 eta 0:00:16
epoch [224/300] batch [1/2] time 0.143 (0.143) data 0.070 (0.070) loss 0.0488 (0.0488) lr 5.8012e-04 eta 0:00:21
epoch [224/300] batch [2/2] time 0.073 (0.108) data 0.000 (0.035) loss 0.2078 (0.1283) lr 5.6727e-04 eta 0:00:16
epoch [225/300] batch [1/2] time 0.143 (0.143) data 0.071 (0.071) loss 0.2809 (0.2809) lr 5.6727e-04 eta 0:00:21
epoch [225/300] batch [2/2] time 0.073 (0.108) data 0.000 (0.035) loss 0.1138 (0.1974) lr 5.5453e-04 eta 0:00:16
epoch [226/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.1631 (0.1631) lr 5.5453e-04 eta 0:00:21
epoch [226/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.1393 (0.1512) lr 5.4190e-04 eta 0:00:16
epoch [227/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.2720 (0.2720) lr 5.4190e-04 eta 0:00:21
epoch [227/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.3796 (0.3258) lr 5.2939e-04 eta 0:00:15
epoch [228/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.2953 (0.2953) lr 5.2939e-04 eta 0:00:20
epoch [228/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.3217 (0.3085) lr 5.1700e-04 eta 0:00:15
epoch [229/300] batch [1/2] time 0.143 (0.143) data 0.070 (0.070) loss 0.0952 (0.0952) lr 5.1700e-04 eta 0:00:20
epoch [229/300] batch [2/2] time 0.073 (0.108) data 0.000 (0.035) loss 0.0721 (0.0836) lr 5.0472e-04 eta 0:00:15
epoch [230/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.2635 (0.2635) lr 5.0472e-04 eta 0:00:20
epoch [230/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.2724 (0.2680) lr 4.9257e-04 eta 0:00:15
epoch [231/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.1191 (0.1191) lr 4.9257e-04 eta 0:00:20
epoch [231/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.2411 (0.1801) lr 4.8054e-04 eta 0:00:15
epoch [232/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.1505 (0.1505) lr 4.8054e-04 eta 0:00:19
epoch [232/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0777 (0.1141) lr 4.6863e-04 eta 0:00:14
epoch [233/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.0571 (0.0571) lr 4.6863e-04 eta 0:00:19
epoch [233/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.1877 (0.1224) lr 4.5684e-04 eta 0:00:14
epoch [234/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.2789 (0.2789) lr 4.5684e-04 eta 0:00:19
epoch [234/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.1119 (0.1954) lr 4.4518e-04 eta 0:00:14
epoch [235/300] batch [1/2] time 0.140 (0.140) data 0.067 (0.067) loss 0.0751 (0.0751) lr 4.4518e-04 eta 0:00:18
epoch [235/300] batch [2/2] time 0.073 (0.107) data 0.000 (0.034) loss 0.0399 (0.0575) lr 4.3365e-04 eta 0:00:13
epoch [236/300] batch [1/2] time 0.146 (0.146) data 0.073 (0.073) loss 0.0647 (0.0647) lr 4.3365e-04 eta 0:00:18
epoch [236/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.0476 (0.0561) lr 4.2224e-04 eta 0:00:14
epoch [237/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.0346 (0.0346) lr 4.2224e-04 eta 0:00:18
epoch [237/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.1317 (0.0831) lr 4.1097e-04 eta 0:00:13
epoch [238/300] batch [1/2] time 0.147 (0.147) data 0.073 (0.073) loss 0.0222 (0.0222) lr 4.1097e-04 eta 0:00:18
epoch [238/300] batch [2/2] time 0.074 (0.110) data 0.000 (0.037) loss 0.1076 (0.0649) lr 3.9982e-04 eta 0:00:13
epoch [239/300] batch [1/2] time 0.146 (0.146) data 0.072 (0.072) loss 0.2691 (0.2691) lr 3.9982e-04 eta 0:00:17
epoch [239/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1485 (0.2088) lr 3.8881e-04 eta 0:00:13
epoch [240/300] batch [1/2] time 0.154 (0.154) data 0.081 (0.081) loss 0.1975 (0.1975) lr 3.8881e-04 eta 0:00:18
epoch [240/300] batch [2/2] time 0.073 (0.114) data 0.000 (0.041) loss 0.0416 (0.1195) lr 3.7793e-04 eta 0:00:13
epoch [241/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.2400 (0.2400) lr 3.7793e-04 eta 0:00:17
epoch [241/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.3479 (0.2940) lr 3.6718e-04 eta 0:00:12
epoch [242/300] batch [1/2] time 0.146 (0.146) data 0.072 (0.072) loss 0.3688 (0.3688) lr 3.6718e-04 eta 0:00:17
epoch [242/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.2375 (0.3032) lr 3.5657e-04 eta 0:00:12
epoch [243/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.0547 (0.0547) lr 3.5657e-04 eta 0:00:16
epoch [243/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0701 (0.0624) lr 3.4609e-04 eta 0:00:12
epoch [244/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.2755 (0.2755) lr 3.4609e-04 eta 0:00:16
epoch [244/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0450 (0.1603) lr 3.3575e-04 eta 0:00:12
epoch [245/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.0417 (0.0417) lr 3.3575e-04 eta 0:00:15
epoch [245/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0565 (0.0491) lr 3.2555e-04 eta 0:00:11
epoch [246/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.0680 (0.0680) lr 3.2555e-04 eta 0:00:15
epoch [246/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.1725 (0.1202) lr 3.1549e-04 eta 0:00:11
epoch [247/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.3782 (0.3782) lr 3.1549e-04 eta 0:00:15
epoch [247/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.2106 (0.2944) lr 3.0557e-04 eta 0:00:11
epoch [248/300] batch [1/2] time 0.144 (0.144) data 0.071 (0.071) loss 0.2495 (0.2495) lr 3.0557e-04 eta 0:00:15
epoch [248/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.0446 (0.1471) lr 2.9580e-04 eta 0:00:11
epoch [249/300] batch [1/2] time 0.145 (0.145) data 0.072 (0.072) loss 0.2321 (0.2321) lr 2.9580e-04 eta 0:00:14
epoch [249/300] batch [2/2] time 0.074 (0.110) data 0.000 (0.036) loss 0.1898 (0.2109) lr 2.8616e-04 eta 0:00:11
epoch [250/300] batch [1/2] time 0.146 (0.146) data 0.072 (0.072) loss 0.3138 (0.3138) lr 2.8616e-04 eta 0:00:14
epoch [250/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.2757 (0.2948) lr 2.7667e-04 eta 0:00:10
epoch [251/300] batch [1/2] time 0.155 (0.155) data 0.080 (0.080) loss 0.1390 (0.1390) lr 2.7667e-04 eta 0:00:15
epoch [251/300] batch [2/2] time 0.073 (0.114) data 0.000 (0.040) loss 0.0699 (0.1044) lr 2.6733e-04 eta 0:00:11
epoch [252/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.1094 (0.1094) lr 2.6733e-04 eta 0:00:14
epoch [252/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1342 (0.1218) lr 2.5813e-04 eta 0:00:10
epoch [253/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.2108 (0.2108) lr 2.5813e-04 eta 0:00:13
epoch [253/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1173 (0.1641) lr 2.4908e-04 eta 0:00:10
epoch [254/300] batch [1/2] time 0.156 (0.156) data 0.082 (0.082) loss 0.0973 (0.0973) lr 2.4908e-04 eta 0:00:14
epoch [254/300] batch [2/2] time 0.073 (0.115) data 0.000 (0.041) loss 0.0545 (0.0759) lr 2.4017e-04 eta 0:00:10
epoch [255/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.5196 (0.5196) lr 2.4017e-04 eta 0:00:13
epoch [255/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.2119 (0.3657) lr 2.3142e-04 eta 0:00:09
epoch [256/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.3266 (0.3266) lr 2.3142e-04 eta 0:00:12
epoch [256/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1804 (0.2535) lr 2.2281e-04 eta 0:00:09
epoch [257/300] batch [1/2] time 0.148 (0.148) data 0.073 (0.073) loss 0.4739 (0.4739) lr 2.2281e-04 eta 0:00:12
epoch [257/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.0607 (0.2673) lr 2.1436e-04 eta 0:00:09
epoch [258/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.3300 (0.3300) lr 2.1436e-04 eta 0:00:12
epoch [258/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.2054 (0.2677) lr 2.0606e-04 eta 0:00:09
epoch [259/300] batch [1/2] time 0.148 (0.148) data 0.074 (0.074) loss 0.1332 (0.1332) lr 2.0606e-04 eta 0:00:12
epoch [259/300] batch [2/2] time 0.073 (0.111) data 0.000 (0.037) loss 0.1549 (0.1440) lr 1.9791e-04 eta 0:00:09
epoch [260/300] batch [1/2] time 0.153 (0.153) data 0.079 (0.079) loss 0.0422 (0.0422) lr 1.9791e-04 eta 0:00:12
epoch [260/300] batch [2/2] time 0.074 (0.113) data 0.000 (0.039) loss 0.2017 (0.1219) lr 1.8991e-04 eta 0:00:09
epoch [261/300] batch [1/2] time 0.155 (0.155) data 0.081 (0.081) loss 0.0345 (0.0345) lr 1.8991e-04 eta 0:00:12
epoch [261/300] batch [2/2] time 0.073 (0.114) data 0.000 (0.040) loss 0.0353 (0.0349) lr 1.8207e-04 eta 0:00:08
epoch [262/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.0613 (0.0613) lr 1.8207e-04 eta 0:00:11
epoch [262/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0757 (0.0685) lr 1.7439e-04 eta 0:00:08
epoch [263/300] batch [1/2] time 0.145 (0.145) data 0.070 (0.070) loss 0.0430 (0.0430) lr 1.7439e-04 eta 0:00:10
epoch [263/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.2496 (0.1463) lr 1.6686e-04 eta 0:00:08
epoch [264/300] batch [1/2] time 0.145 (0.145) data 0.070 (0.070) loss 0.2053 (0.2053) lr 1.6686e-04 eta 0:00:10
epoch [264/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.2680 (0.2366) lr 1.5949e-04 eta 0:00:07
epoch [265/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.1086 (0.1086) lr 1.5949e-04 eta 0:00:10
epoch [265/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.2791 (0.1938) lr 1.5228e-04 eta 0:00:07
epoch [266/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.2106 (0.2106) lr 1.5228e-04 eta 0:00:10
epoch [266/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.1416 (0.1761) lr 1.4522e-04 eta 0:00:07
epoch [267/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.2474 (0.2474) lr 1.4522e-04 eta 0:00:09
epoch [267/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.0355 (0.1414) lr 1.3833e-04 eta 0:00:07
epoch [268/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.0227 (0.0227) lr 1.3833e-04 eta 0:00:09
epoch [268/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.0747 (0.0487) lr 1.3159e-04 eta 0:00:07
epoch [269/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.1861 (0.1861) lr 1.3159e-04 eta 0:00:09
epoch [269/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.4085 (0.2973) lr 1.2502e-04 eta 0:00:06
epoch [270/300] batch [1/2] time 0.146 (0.146) data 0.072 (0.072) loss 0.0907 (0.0907) lr 1.2502e-04 eta 0:00:08
epoch [270/300] batch [2/2] time 0.074 (0.110) data 0.000 (0.036) loss 0.2475 (0.1691) lr 1.1861e-04 eta 0:00:06
epoch [271/300] batch [1/2] time 0.150 (0.150) data 0.075 (0.075) loss 0.2671 (0.2671) lr 1.1861e-04 eta 0:00:08
epoch [271/300] batch [2/2] time 0.074 (0.112) data 0.000 (0.038) loss 0.4470 (0.3570) lr 1.1236e-04 eta 0:00:06
epoch [272/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.0390 (0.0390) lr 1.1236e-04 eta 0:00:08
epoch [272/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1954 (0.1172) lr 1.0627e-04 eta 0:00:06
epoch [273/300] batch [1/2] time 0.145 (0.145) data 0.070 (0.070) loss 0.2047 (0.2047) lr 1.0627e-04 eta 0:00:07
epoch [273/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.2353 (0.2200) lr 1.0035e-04 eta 0:00:05
epoch [274/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.1725 (0.1725) lr 1.0035e-04 eta 0:00:07
epoch [274/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.1412 (0.1568) lr 9.4591e-05 eta 0:00:05
epoch [275/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.0389 (0.0389) lr 9.4591e-05 eta 0:00:07
epoch [275/300] batch [2/2] time 0.074 (0.110) data 0.000 (0.036) loss 0.0509 (0.0449) lr 8.8998e-05 eta 0:00:05
epoch [276/300] batch [1/2] time 0.145 (0.145) data 0.071 (0.071) loss 0.1360 (0.1360) lr 8.8998e-05 eta 0:00:07
epoch [276/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.035) loss 0.0648 (0.1004) lr 8.3571e-05 eta 0:00:05
epoch [277/300] batch [1/2] time 0.147 (0.147) data 0.073 (0.073) loss 0.3565 (0.3565) lr 8.3571e-05 eta 0:00:06
epoch [277/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.037) loss 0.1914 (0.2740) lr 7.8310e-05 eta 0:00:05
epoch [278/300] batch [1/2] time 0.147 (0.147) data 0.072 (0.072) loss 0.2173 (0.2173) lr 7.8310e-05 eta 0:00:06
epoch [278/300] batch [2/2] time 0.073 (0.110) data 0.000 (0.036) loss 0.1556 (0.1865) lr 7.3215e-05 eta 0:00:04
epoch [279/300] batch [1/2] time 0.146 (0.146) data 0.071 (0.071) loss 0.2895 (0.2895) lr 7.3215e-05 eta 0:00:06
epoch [279/300] batch [2/2] time 0.073 (0.109) data 0.000 (0.036) loss 0.2515 (0.2705) lr 6.8289e-05 eta 0:00:04
epoch [280/300] batch [1/2] time 0.151 (0.151) data 0.072 (0.072) loss 0.0875 (0.0875) lr 6.8289e-05 eta 0:00:06
epoch [280/300] batch [2/2] time 0.077 (0.114) data 0.000 (0.036) loss 0.0563 (0.0719) lr 6.3530e-05 eta 0:00:04
epoch [281/300] batch [1/2] time 0.149 (0.149) data 0.072 (0.072) loss 0.2313 (0.2313) lr 6.3530e-05 eta 0:00:05
epoch [281/300] batch [2/2] time 0.077 (0.113) data 0.000 (0.036) loss 0.1446 (0.1880) lr 5.8940e-05 eta 0:00:04
epoch [282/300] batch [1/2] time 0.150 (0.150) data 0.072 (0.072) loss 0.0610 (0.0610) lr 5.8940e-05 eta 0:00:05
epoch [282/300] batch [2/2] time 0.077 (0.113) data 0.000 (0.036) loss 0.0842 (0.0726) lr 5.4519e-05 eta 0:00:04
epoch [283/300] batch [1/2] time 0.149 (0.149) data 0.072 (0.072) loss 0.1243 (0.1243) lr 5.4519e-05 eta 0:00:05
epoch [283/300] batch [2/2] time 0.077 (0.113) data 0.000 (0.036) loss 0.3226 (0.2234) lr 5.0267e-05 eta 0:00:03
epoch [284/300] batch [1/2] time 0.150 (0.150) data 0.072 (0.072) loss 0.1177 (0.1177) lr 5.0267e-05 eta 0:00:04
epoch [284/300] batch [2/2] time 0.077 (0.113) data 0.000 (0.036) loss 0.0254 (0.0716) lr 4.6185e-05 eta 0:00:03
epoch [285/300] batch [1/2] time 0.149 (0.149) data 0.071 (0.071) loss 0.3238 (0.3238) lr 4.6185e-05 eta 0:00:04
epoch [285/300] batch [2/2] time 0.077 (0.113) data 0.000 (0.036) loss 0.2957 (0.3097) lr 4.2274e-05 eta 0:00:03
epoch [286/300] batch [1/2] time 0.148 (0.148) data 0.071 (0.071) loss 0.1239 (0.1239) lr 4.2274e-05 eta 0:00:04
epoch [286/300] batch [2/2] time 0.077 (0.113) data 0.000 (0.036) loss 0.2169 (0.1704) lr 3.8533e-05 eta 0:00:03
epoch [287/300] batch [1/2] time 0.150 (0.150) data 0.073 (0.073) loss 0.1082 (0.1082) lr 3.8533e-05 eta 0:00:04
epoch [287/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.037) loss 0.1235 (0.1159) lr 3.4964e-05 eta 0:00:02
epoch [288/300] batch [1/2] time 0.150 (0.150) data 0.072 (0.072) loss 0.1794 (0.1794) lr 3.4964e-05 eta 0:00:03
epoch [288/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.036) loss 0.1717 (0.1755) lr 3.1566e-05 eta 0:00:02
epoch [289/300] batch [1/2] time 0.149 (0.149) data 0.071 (0.071) loss 0.0907 (0.0907) lr 3.1566e-05 eta 0:00:03
epoch [289/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.036) loss 0.0313 (0.0610) lr 2.8340e-05 eta 0:00:02
epoch [290/300] batch [1/2] time 0.151 (0.151) data 0.073 (0.073) loss 0.1174 (0.1174) lr 2.8340e-05 eta 0:00:03
epoch [290/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.036) loss 0.1370 (0.1272) lr 2.5287e-05 eta 0:00:02
epoch [291/300] batch [1/2] time 0.150 (0.150) data 0.073 (0.073) loss 0.2104 (0.2104) lr 2.5287e-05 eta 0:00:02
epoch [291/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.037) loss 0.2450 (0.2277) lr 2.2406e-05 eta 0:00:02
epoch [292/300] batch [1/2] time 0.152 (0.152) data 0.074 (0.074) loss 0.0625 (0.0625) lr 2.2406e-05 eta 0:00:02
epoch [292/300] batch [2/2] time 0.078 (0.115) data 0.000 (0.037) loss 0.1723 (0.1174) lr 1.9699e-05 eta 0:00:01
epoch [293/300] batch [1/2] time 0.151 (0.151) data 0.073 (0.073) loss 0.2475 (0.2475) lr 1.9699e-05 eta 0:00:02
epoch [293/300] batch [2/2] time 0.078 (0.115) data 0.000 (0.037) loss 0.0804 (0.1639) lr 1.7164e-05 eta 0:00:01
epoch [294/300] batch [1/2] time 0.152 (0.152) data 0.075 (0.075) loss 0.2469 (0.2469) lr 1.7164e-05 eta 0:00:01
epoch [294/300] batch [2/2] time 0.077 (0.115) data 0.000 (0.037) loss 0.3157 (0.2813) lr 1.4803e-05 eta 0:00:01
epoch [295/300] batch [1/2] time 0.150 (0.150) data 0.073 (0.073) loss 0.0565 (0.0565) lr 1.4803e-05 eta 0:00:01
epoch [295/300] batch [2/2] time 0.077 (0.114) data 0.000 (0.036) loss 0.1893 (0.1229) lr 1.2616e-05 eta 0:00:01
epoch [296/300] batch [1/2] time 0.149 (0.149) data 0.072 (0.072) loss 0.0734 (0.0734) lr 1.2616e-05 eta 0:00:01
epoch [296/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.036) loss 0.1750 (0.1242) lr 1.0604e-05 eta 0:00:00
epoch [297/300] batch [1/2] time 0.151 (0.151) data 0.073 (0.073) loss 0.0392 (0.0392) lr 1.0604e-05 eta 0:00:01
epoch [297/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.037) loss 0.0703 (0.0548) lr 8.7650e-06 eta 0:00:00
epoch [298/300] batch [1/2] time 0.149 (0.149) data 0.071 (0.071) loss 0.1621 (0.1621) lr 8.7650e-06 eta 0:00:00
epoch [298/300] batch [2/2] time 0.078 (0.113) data 0.000 (0.036) loss 0.2014 (0.1817) lr 7.1009e-06 eta 0:00:00
epoch [299/300] batch [1/2] time 0.150 (0.150) data 0.072 (0.072) loss 0.0786 (0.0786) lr 7.1009e-06 eta 0:00:00
epoch [299/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.036) loss 0.1838 (0.1312) lr 5.6114e-06 eta 0:00:00
epoch [300/300] batch [1/2] time 0.150 (0.150) data 0.072 (0.072) loss 0.0951 (0.0951) lr 5.6114e-06 eta 0:00:00
epoch [300/300] batch [2/2] time 0.078 (0.114) data 0.000 (0.036) loss 0.1030 (0.0990) lr 4.2968e-06 eta 0:00:00
Checkpoint saved to output/base2new/train_base/eurosat/shots_16/LASP/vit_b16_c4_ep300_batch32_cls_t2t_5_wcl_25_g1_b_lr32/seed2/prompt_learner/model.pth.tar-300
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 4,200
* correct: 3,997
* accuracy: 95.2%
* error: 4.8%
* macro_f1: 95.2%
Elapsed: 0:01:18
